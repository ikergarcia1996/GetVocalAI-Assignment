model_name_or_path: FacebookAI/xlm-roberta-base

train_dataset: ../data/daily_dialog_train.jsonl
validation_dataset: ../data/daily_dialog_validation.jsonl
test_datasets: 
  - ../data/daily_dialog_test.jsonl
  - ../data/mutual_validation.jsonl

output_dir: results/xlmroberta
do_train: true
do_eval: true
do_predict: true


per_device_train_batch_size: 32
per_device_eval_batch_size: 32
gradient_accumulation_steps: 1

learning_rate: 1e-5
warmup_steps: 100
num_train_epochs: 3
lr_scheduler_type: cosine

logging_steps: 10

bf16: false
fp16: true # XLM-Roberta was trained with fp16